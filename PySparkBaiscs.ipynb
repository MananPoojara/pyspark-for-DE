{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnYwXfNApdc3XyIPcUEdDP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MananPoojara/pyspark-for-DE/blob/main/PySparkBaiscs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJEtkofxXVNg",
        "outputId": "57bbc764-c2c5-4863-d219-8644498f3a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Download the Dataset"
      ],
      "metadata": {
        "id": "OxEU8ejJX9dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pyspark --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8rMielnaMwU",
        "outputId": "8a359eaf-999b-4d19-e691-54a5099a36c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.1\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.27\n",
            "Branch HEAD\n",
            "Compiled by user heartsavior on 2024-02-15T11:24:58Z\n",
            "Revision fd86f85e181fc2dc0f50a096855acf83a6cc5d9c\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/markumreed/colab_pyspark/main/WMT.csv >> WMT.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xruTz4KDYCUt",
        "outputId": "86f6c1c6-e486-45a3-cd76-2d0a26523cda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 89556  100 89556    0     0   351k      0 --:--:-- --:--:-- --:--:--  352k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If Someone Know Pandas you will fimiler with some of the function and Dataframes so same we are doing here but spark has it's seesions so"
      ],
      "metadata": {
        "id": "QqIremM6YWVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"app1\").getOrCreate() #help for creating session\n",
        "df = spark.read.csv(\"WMT.csv\", header=True, inferSchema=True) #spark.read.csv for reading csv and we store in Dataframe\n",
        "df.show() # same as pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huHva1bxYVk8",
        "outputId": "b8ee3f89-014a-4ef9-9429-dfd3435f1f43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|      Date|     Open|     High|      Low|    Close|Adj Close|  Volume|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|2016-01-20|61.799999|62.330002|60.200001|    60.84|53.990601|17369100|\n",
            "|2016-01-21|    60.98|62.790001|    60.91|61.880001|54.913509|12089200|\n",
            "|2016-01-22|62.439999|63.259998|62.130001|62.689999|55.632324| 9197500|\n",
            "|2016-01-25|62.779999|    63.82|62.549999|63.450001|56.306763|12823400|\n",
            "|2016-01-26|63.360001|64.470001|63.259998|     64.0|56.794834| 9441200|\n",
            "|2016-01-27|64.099998|    65.18|63.889999|63.950001|56.750477|10214300|\n",
            "|2016-01-28|64.029999|64.510002|    63.43|64.220001| 56.99007|11278300|\n",
            "|2016-01-29|    64.75|66.529999|64.739998|66.360001|58.889149|16439100|\n",
            "|2016-02-01|65.910004|    67.93|65.889999|     67.5| 59.90081|14728400|\n",
            "|2016-02-02|67.300003|67.839996|66.279999|66.860001|59.332867|13585900|\n",
            "|2016-02-03|67.309998|     67.5|    65.07|66.269997| 58.80928|12315600|\n",
            "|2016-02-04|65.760002|66.550003|65.010002|66.419998| 58.94239|12833400|\n",
            "|2016-02-05|66.860001|67.529999|65.879997|     67.0|  59.4571|14196500|\n",
            "|2016-02-08|     66.5|67.150002|65.160004|66.900002|59.368362|20743600|\n",
            "|2016-02-09|65.489998|66.410004|    64.68|65.809998|58.401058|14642400|\n",
            "|2016-02-10|66.190002|66.589996|65.650002|65.790001| 58.38332| 9709300|\n",
            "|2016-02-11|65.019997|65.760002|64.779999|    65.32|57.966228|11186700|\n",
            "|2016-02-12|65.519997|    66.25|64.870003|    66.18|58.729424| 9695500|\n",
            "|2016-02-16|66.610001|66.800003|     65.5|65.900002|58.480934|11360500|\n",
            "|2016-02-17|66.099998|66.610001|65.809998|66.110001|58.667301|12426700|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema() #datatypes of dataframe/files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkbrFB5fbMYh",
        "outputId": "ff3b05d8-e1e4-4804-f89f-98154fa886d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4kwiaSob7O7",
        "outputId": "a5663f04-e369-43cc-b6f4-105db402848a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Date=datetime.date(2016, 1, 20), Open=61.799999, High=62.330002, Low=60.200001, Close=60.84, Adj Close=53.990601, Volume=17369100),\n",
              " Row(Date=datetime.date(2016, 1, 21), Open=60.98, High=62.790001, Low=60.91, Close=61.880001, Adj Close=54.913509, Volume=12089200),\n",
              " Row(Date=datetime.date(2016, 1, 22), Open=62.439999, High=63.259998, Low=62.130001, Close=62.689999, Adj Close=55.632324, Volume=9197500),\n",
              " Row(Date=datetime.date(2016, 1, 25), Open=62.779999, High=63.82, Low=62.549999, Close=63.450001, Adj Close=56.306763, Volume=12823400),\n",
              " Row(Date=datetime.date(2016, 1, 26), Open=63.360001, High=64.470001, Low=63.259998, Close=64.0, Adj Close=56.794834, Volume=9441200)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fileter Data"
      ],
      "metadata": {
        "id": "S5LEAF_kb-OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(\"close < 62\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHPFnqTxcALf",
        "outputId": "680a4a60-2a6c-4200-88ce-b56ef65a1fb3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|      Date|     Open|     High|      Low|    Close|Adj Close|  Volume|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|2016-01-20|61.799999|62.330002|60.200001|    60.84|53.990601|17369100|\n",
            "|2016-01-21|    60.98|62.790001|    60.91|61.880001|54.913509|12089200|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(\"close < 62\").select(\"open\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2deMedaccgZr",
        "outputId": "8da2bd30-6fb8-4aef-f273-de9a0f0d549e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|     open|\n",
            "+---------+\n",
            "|61.799999|\n",
            "|    60.98|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(\"close < 62\").select([\"open\", \"Date\"]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhuvSeaZcpuk",
        "outputId": "7c89f1c2-fb13-4bd0-abbb-4a68f3b304a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|     open|      Date|\n",
            "+---------+----------+\n",
            "|61.799999|2016-01-20|\n",
            "|    60.98|2016-01-21|\n",
            "+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "Hx-J3DpedZwh",
        "outputId": "f7189bf1-2a05-481c-de88-0e2c3ad13f4d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df[\"close\"] < 62).show() #another way like pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyTsxIVPdcqf",
        "outputId": "5089ae85-9974-4e53-b430-b32f75bced80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|      Date|     Open|     High|      Low|    Close|Adj Close|  Volume|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|2016-01-20|61.799999|62.330002|60.200001|    60.84|53.990601|17369100|\n",
            "|2016-01-21|    60.98|62.790001|    60.91|61.880001|54.913509|12089200|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter((df[\"close\"] < 62) & (df[\"open\"] > 60)).show()\n",
        "df.filter((df[\"close\"] < 62) | (df[\"open\"] > 60)).show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwMBnKKAds6U",
        "outputId": "cc982334-da01-4c50-e276-08c3d61302f0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|      Date|     Open|     High|      Low|    Close|Adj Close|  Volume|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|2016-01-20|61.799999|62.330002|60.200001|    60.84|53.990601|17369100|\n",
            "|2016-01-21|    60.98|62.790001|    60.91|61.880001|54.913509|12089200|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|      Date|     Open|     High|      Low|    Close|Adj Close|  Volume|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|2016-01-20|61.799999|62.330002|60.200001|    60.84|53.990601|17369100|\n",
            "|2016-01-21|    60.98|62.790001|    60.91|61.880001|54.913509|12089200|\n",
            "|2016-01-22|62.439999|63.259998|62.130001|62.689999|55.632324| 9197500|\n",
            "|2016-01-25|62.779999|    63.82|62.549999|63.450001|56.306763|12823400|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df[\"close\"] == 66.860001).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i9_2vZteBMe",
        "outputId": "694f6761-e369-48b8-f6c3-cd2ab5687ab6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|      Date|     Open|     High|      Low|    Close|Adj Close|  Volume|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "|2016-02-02|67.300003|67.839996|66.279999|66.860001|59.332867|13585900|\n",
            "+----------+---------+---------+---------+---------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = df.filter(df[\"close\"] == 66.860001).collect() #collect can make or store data as python object\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAJwLOAXeHBt",
        "outputId": "6a714778-67ca-4f5f-f01b-866ebec70449"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Date=datetime.date(2016, 2, 2), Open=67.300003, High=67.839996, Low=66.279999, Close=66.860001, Adj Close=59.332867, Volume=13585900)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(result)\n",
        "type(result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "J7t6I8XjetO5",
        "outputId": "41c8d374-59d1-417b-ad30-8dd1fd48a5d9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.types.Row"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.types.Row</b><br/>def __call__(*args: Any) -&gt; &#x27;Row&#x27;</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/types.py</a>A row in :class:`DataFrame`.\n",
              "The fields in it can be accessed:\n",
              "\n",
              "* like attributes (``row.key``)\n",
              "* like dictionary values (``row[key]``)\n",
              "\n",
              "``key in row`` will search through row keys.\n",
              "\n",
              "Row can be used to create a row object by using named arguments.\n",
              "It is not allowed to omit a named argument to represent that the value is\n",
              "None or missing. This should be explicitly set to None in this case.\n",
              "\n",
              ".. versionchanged:: 3.0.0\n",
              "    Rows created from named arguments no longer have\n",
              "    field names sorted alphabetically and will be ordered in the position as\n",
              "    entered.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from pyspark.sql import Row\n",
              "&gt;&gt;&gt; row = Row(name=&quot;Alice&quot;, age=11)\n",
              "&gt;&gt;&gt; row\n",
              "Row(name=&#x27;Alice&#x27;, age=11)\n",
              "&gt;&gt;&gt; row[&#x27;name&#x27;], row[&#x27;age&#x27;]\n",
              "(&#x27;Alice&#x27;, 11)\n",
              "&gt;&gt;&gt; row.name, row.age\n",
              "(&#x27;Alice&#x27;, 11)\n",
              "&gt;&gt;&gt; &#x27;name&#x27; in row\n",
              "True\n",
              "&gt;&gt;&gt; &#x27;wrong_key&#x27; in row\n",
              "False\n",
              "\n",
              "Row also can be used to create another Row like class, then it\n",
              "could be used to create Row objects, such as\n",
              "\n",
              "&gt;&gt;&gt; Person = Row(&quot;name&quot;, &quot;age&quot;)\n",
              "&gt;&gt;&gt; Person\n",
              "&lt;Row(&#x27;name&#x27;, &#x27;age&#x27;)&gt;\n",
              "&gt;&gt;&gt; &#x27;name&#x27; in Person\n",
              "True\n",
              "&gt;&gt;&gt; &#x27;wrong_key&#x27; in Person\n",
              "False\n",
              "&gt;&gt;&gt; Person(&quot;Alice&quot;, 11)\n",
              "Row(name=&#x27;Alice&#x27;, age=11)\n",
              "\n",
              "This form can also be used to create rows as tuple values, i.e. with unnamed\n",
              "fields.\n",
              "\n",
              "&gt;&gt;&gt; row1 = Row(&quot;Alice&quot;, 11)\n",
              "&gt;&gt;&gt; row2 = Row(name=&quot;Alice&quot;, age=11)\n",
              "&gt;&gt;&gt; row1 == row2\n",
              "True</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2205);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0].asDict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4FWpWN1fAhf",
        "outputId": "d105053f-5278-47b7-ac4f-0ef198afef09"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Date': datetime.date(2016, 2, 2),\n",
              " 'Open': 67.300003,\n",
              " 'High': 67.839996,\n",
              " 'Low': 66.279999,\n",
              " 'Close': 66.860001,\n",
              " 'Adj Close': 59.332867,\n",
              " 'Volume': 13585900}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in result[0]:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwmzRB9zfIhA",
        "outputId": "051f9879-8f30-4f67-baa0-86b9e23f1709"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2016-02-02\n",
            "67.300003\n",
            "67.839996\n",
            "66.279999\n",
            "66.860001\n",
            "59.332867\n",
            "13585900\n"
          ]
        }
      ]
    }
  ]
}